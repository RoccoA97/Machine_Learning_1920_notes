\providecommand{\main}{../../main}
\providecommand{\figpath}[1]{\main/../lessons/#1}
\documentclass[../../main/main.tex]{subfiles}

\begin{document}

\begin{definition}[Homomorphism]
It is a map $\varphi: G \to G'$ (where $G$ and $G'$ are groups) which is compatible with the group structure, so such as:
\begin{equation*}
\forall g_1, g_2 \in G \qquad \varphi(g_1) \, \phi(g_2) = \varphi(g_1 \cdot g_2)
\end{equation*}
In particular, the following relations hold:
\begin{equation*}
\varphi(e) = e' , \qquad (\varphi(g))^{-1}=\varphi(g^{-1})
\end{equation*}
\end{definition}


\begin{definition}[Isomorphism]
It's a homomorphism such as $\varphi$ is a one-to-one function, so each $g \in G$ has only one representative. When it happens, $G \simeq G'$.
\end{definition}

\begin{definition}[Automorphism]
An automorphism is an isomorphism $\varphi: G \to G$ from a group to itself.
\end{definition}

\begin{definition}[Kernel]
Given $\varphi: G \to G'$, its kernel is the set: \newline
\begin{equation}
Ker(\varphi)=\{ g \in G : \varphi(g)=e' \} = \varphi^{-1}(e')
\end{equation}
\end{definition}

One of the properties of the kernel is the following Lemma:
\vspace{0.5\baselineskip}\newline
\textbf{Lemma} $ Ker(\varphi)$ is a normal subgroup.
\begin{proof}
\begin{equation*}
h \in Ker(\varphi), \, g \in G
\end{equation*}
For the properties of a homomorphy:
\begin{equation*}
\varphi(ghg^{-1}) = \varphi(g) \varphi(h) \varphi(g^{-1}) = \varphi(g) e' \varphi^{-1}(g) = e'
\end{equation*}
So, $ghg^{-1} \in Ker(\varphi)$
\end{proof}

\chapter{Representation Theory}
\begin{definition}[Representation]
A representation of the group $G$ acting on a N-dimensional vector space $\mathbb{V} \owns v$ is a homomorphism $D \, : \, G \to GL(N, \mathbb{K}, \mathbb{V})$ ($\mathbb{K}$=$\mathbb{R}$ or $\mathbb{C}$), so it associates an element of a group to a $N \times N$ matrix with real or complex elements acting on $\mathbb{V}$.
\end{definition}
Since it is a homomorphism, it preserves the group product:
\begin{equation*}
D(g_1 \cdot g_2) = D(g_1) \, D(g_2)
\end{equation*}
if we consider the right side of the equation as a matrix product. \newline
A representation has the following properties:
\begin{enumerate}
\item $e \in G \implies D(e)=\mathbb{1}_{N \times N}$ ;
\item $D(g^{-1})=D(g)^{-1}$ (inverse matrix)
\end{enumerate}
$\iff$ The set of $D_{i} \equiv D(g_{i})$ forms a group $G' \simeq G$ which is \textbf{faithful representation}, so an invertible map making a one-to-onecorrespondence between $G$ and $\mathbb{V}$. \newline
\begin{itemize}
\item Each group has a one dimensional representation, which is trivial and not faithful:
\begin{equation*}
\forall g_i \in G \qquad D(g_i) = 1 \in \mathbb{R}
\end{equation*}
\item \textbf{Unitary representations} $D(g) \in U(N, \mathbb{C})$ have the property:
\begin{equation*}
D(g) \, D^{\dagger}(g) = D^{\dagger}(g) D(g) = \mathbb{1}
\end{equation*}
\end{itemize}

\begin{definition}[Reducible representations]
They are representations which are equivalent to a triangular matrix:
\begin{equation*}
\begin{pmatrix}
 - & - & ... & - & - \\
0 & - & ... & - & - \\
0 & 0 & ... & - & - \\
& & \vdots & & \\
0 & 0 & ... & 0 & -
\end{pmatrix}
\end{equation*}
A representation $\tilde{D}(g)$ is \textbf{fully/completely reducible} if it is equivalent to a block-diagonal matrix, so if $\forall g \in G \exists ! S \, : \, S\tilde{G}S^{-1}=D(g)$ such as $D(g)$ is block diagonal.
\end{definition}

\begin{example}
Consider the vector:
\begin{equation*}
\vec{v} = \begin{pmatrix} 	v_1	\\	v_2	\end{pmatrix} = v_1 \widehat{e_1} + v_2 \widehat{e_2}
\end{equation*}
and the triangular matrix:
\begin{equation*}
\begin{pmatrix} 	a & b	\\	0 & c	\end{pmatrix}
\end{equation*}
If we consider:
\begin{equation*}
\begin{pmatrix} 	a & b	\\	0 & c	\end{pmatrix} \widehat{e_1} = \begin{pmatrix} 	a	\\ 0	\end{pmatrix} = a \widehat{e_1}
\end{equation*}
So, the subspace generated by $\widehat{e_1}$ is left invariant by an upper triangular matrix. The same doesn't hold for the subspace generated by $\widehat{e_2}$. Indeed:
\begin{equation*}
\begin{pmatrix} 	a & b	\\	0 & c	\end{pmatrix} \widehat{e_2} = b \widehat{e_1} + c \widehat{e_2}
\end{equation*}
A diagonal matrix leaves both the subspaces invariant.
\end{example}
With a fully reducible matrix:
\begin{equation*}
D_{i}=(n_i \times n_i) \text{ matrix with } N=\sum_{i=1}^k n_i
\end{equation*}
with $k=$the number of blocks in the matrix. Furthermore:
\begin{equation*}
D(g) = \oplus_{i=1}^k D_i(g_i) \iff \mathbb{W}_1 , \mathbb{W}_2 , \, ... \, , \mathbb{W}_k \subset \mathbb{V} \, , \, \mathbb{V} = \oplus_{i=1}^k \mathbb{W}_i
\end{equation*}

\begin{definition}[Irreducible representation]
A representation is irreducible if $\nexists S$ : $SDS^{-1}$ is block-diagonal.
\end{definition}

\textbf{Schur's Lemma} If $D(g)$ is an irreducible representation of $G$ over $\mathbb{V}$ and if $\exists A$ matrix : $A \mathbb{V} \to \mathbb{V}$ such that $\forall g \in G \, AD(g)=D(g)A$ $\implies \, A$ is proportional to $\mathbb{1}_{N \times N}$. Equivalently, $\exists \lambda \in \mathbb{C} \, : A = \lambda \mathbb{1}_{N \times N}$.

\chapter{Lie Groups and Lie Algebras}
\begin{definition}[Lie group]
It is a continuous group G made of $\{A(\vec{\alpha}) \in G, \vec{\alpha}=\{\alpha_i \}_{i=1,...,n} \text{real valued}\}$ with the following properties:
\begin{enumerate}
\item \textbf{Identity} $e = A(\vec{0})$;
\item \textbf{Closure} $A(\vec{\alpha})\, A(\vec{\beta})= A(\vec{\gamma})$ ($\exists f$ differentiable function such as $\vec{\gamma}=f(\vec{\alpha}, \vec{\beta})$ );
\item \textbf{Inverse} $\forall \vec{\alpha}$, $A(\vec{\alpha})^{-1}=A(\vec{\alpha '})$ and $\vec{\alpha} \to \vec{\alpha ' }$ is differentiable;
\item \textbf{Associativity} $\forall \vec{\alpha}, \vec{\beta}, \vec{\gamma}$, $(A(\vec{\alpha}) \, A(\vec{\beta})) \,  A(\vec{\gamma}) = A(\vec{\alpha}) \, ( A(\vec{\beta})\,A(\vec{\gamma}) )  $
\end{enumerate}
\end{definition}
We can study the properties of the Lie groups through Lie algebras, by expanding the element of the group around the identical matrix (it's the study of the local behaviour).
\begin{equation*}
D(\vec{0}) = \mathbb{1}_{N \times N}
\end{equation*}
So, if we consider the Taylor expansion:
\begin{equation*}
D(\vec{\alpha}) \simeq \mathbb{1} + i \, \alpha_a \,  T^a
\end{equation*}
The quantities $T^a$ are the \textbf{generators of the Lie algebra}. Equivalently, they are defined through the relation:
\begin{equation*}
T^{a}= i \frac{\partial}{\partial \alpha_a} D(\vec{\alpha}) \Big|_{\vec{\alpha}=\vec{0}}
\end{equation*}
There exists a trivial representation, when $T^a=0 \forall a$. \newline
Moreover, the generators have the properties:
\begin{itemize}
\item $\{T^a \}_{a=1,...,n}$ form a basis of a vector space $\mathfrak{g} \equiv Alg(G)$, which means:
\begin{equation*}
T^a, \, T^b \in \mathfrak{g}  \implies c_a\, T^a + c_b\, T^b \in \mathfrak{g} , \, c_a, c_b \in \mathbb{R}
\end{equation*}
\item $[T^a, T^b] \in \mathfrak{g} \implies [T^a, T^b] \equiv i \, f^{abc} \, T^{c}$ where $f^{abc}=-f^{bac}$ (anti-symmetric) $\iff$ $\mathfrak{g}$ is completely characterized by the quantities $f^{abc}$, which are called \textbf{structure constants}; they depend on the group.
\end{itemize}

\section{Exponential representation}
I can represent in a unique way every element of the group once I know the generator, coming back from the algebra to the corresponding group.
\begin{equation*}
D(\vec{\alpha}) \equiv e^{i \alpha_a T^a} = e^{i \alpha \cdot T} = lim_{k \to \infty} \Big( \mathbb{1} + i \frac{\vec{\alpha}}{k} \cdot \vec{T}\Big)^k
\end{equation*}
Consider the relationship:
\begin{equation*}
e^{i \vec{\alpha} \cdot \vec{T}} e^{i \vec{\beta} \cdot \vec{T}} = e^{i \vec{\delta} \cdot \vec{T}}
\end{equation*}
In general, $\vec{\delta} \ne \vec{\alpha} + \vec{\beta}$ if they do not commute. This same equation can be rewritten as:
\begin{equation*}
\Big[\mathbb{1}+i\vec{\alpha}\cdot \vec{T} -\frac{1}{2} (\vec{\alpha}\cdot \vec{T})^2+...\Big)\Big[\mathbb{1}+i\vec{\beta}\cdot \vec{T} -\frac{1}{2} (\vec{\beta}\cdot \vec{T})^2+...\Big) = \Big[\mathbb{1}+i\vec{\delta}\cdot \vec{T} -\frac{1}{2} (\vec{\delta}\cdot \vec{T})^2+...\Big)
\end{equation*}
\begin{equation*}
\implies i\vec{\delta}\cdot \vec{T}=i\vec{\alpha}\cdot \vec{T} + i\vec{\beta}\cdot \vec{T} - (\vec{\alpha}\cdot \vec{T})(\vec{\beta}\cdot \vec{T})+...= i\vec{\alpha}\cdot \vec{T} + i\vec{\beta}\cdot \vec{T} - \frac{1}{2} [\vec{\alpha}\cdot \vec{T}, \vec{\beta}\cdot \vec{T}] +...
\end{equation*}
The last equality holds thanks to the BHC equation. This implies:
\begin{equation*}
[\alpha_a T^a, \beta_bT^b]=-2i(\delta_c-\alpha_c-\beta_c)T^c\equiv i\gamma_c T^c
\end{equation*}
\begin{equation*}
\gamma_c \equiv -2 (\delta_c - \alpha_c - \beta_c) \equiv \alpha_a \beta_b f^{abc}
\end{equation*}

\begin{itemize}
\item \textbf{Jacobi Identity}
\begin{equation*}
[[T^a, T^b], T^c]+[[T^b, T^c], T^a]+[[T^c, T^a], T^b]=0 \iff f^{abd}f^{dce}+ f^{bcd}f^{dae}+ f^{cad}f^{dbe}=0
\end{equation*}
\begin{proof}
$[[T^a, T^b], T^c]=if^{abd}[T^d, T^c] = - f^{abd} f^{dce} T^{e}$
\end{proof}
\end{itemize}
There are two main representations:
\begin{enumerate}
\item \textbf{Fundamental representation}: $D(g)$ is a $N \times N$ matrix acting on a vector;
\item \textbf{Adjoint representaton} (using $f^{abc}$): $(\mathbb{T}^a)_{bc} \equiv f^{abc} \implies [\mathbb{T}^a, \mathbb{T}^b]=i f^{abc} \mathbb{T}^c$
\end{enumerate}

\textbf{Killing form} \newline
\begin{equation*}
g^{ab}=f^{acd}f^{bdc}
\end{equation*}
$g$ is a metric matrix which is used to build the so-called "Casimir operators".

\begin{definition}[Casimir operator]
\begin{equation*}
C \equiv g_{ab} T^a T^b
\end{equation*}
They are such as $[C, T^a]=0\, \forall T^a \in G$.
\end{definition}

\begin{example}
\begin{itemize}
\item $SO(2, \mathbb{R})$: it is the group of the matrices $R(\theta)=\begin{pmatrix}
					\cos{\theta}	&	\sin{\theta}	\\
					-\sin{\theta}	&	\cos{\theta}
				\end{pmatrix}$, which are rotations in the $(x, y)$ plane ($\theta \in [0, 2\pi )$). \newline
We can write:
\begin{equation*}
R(\theta)=\mathbb{1}+ i \theta \begin{pmatrix}
					0	&	-i	\\
					i	&	0
				\end{pmatrix}
\end{equation*}
The matrix $\begin{pmatrix}
					0	&	-i	\\
					i	&	0
				\end{pmatrix}$ is the generator of the group, so it is classified by only one generator (the number of generators is equal to the one of free parameters). \newline
It is then isomorphic to the group $U(1)$ whose elements are $e^{i \theta}$ (rotations in the $(x, y)$ plane in polar coordinates). \newline
Moreorve, they are both abelian groups (2D rotations commute).
\item $E_2$
\end{itemize}
\end{example}





\end{document}
